{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict\n",
    "from itertools import product\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, \\\n",
    "    confusion_matrix, precision_recall_fscore_support, \\\n",
    "    roc_auc_score, matthews_corrcoef, average_precision_score, \\\n",
    "    log_loss, brier_score_loss\n",
    "import scipy.stats.mstats as ms\n",
    "from Funcs.Utility import *\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    y_true: np.ndarray,\n",
    "    y_pred: np.ndarray,\n",
    "    y_prob: np.ndarray,\n",
    "    classes: np.ndarray\n",
    ") -> Dict[str, any]:\n",
    "\n",
    "    R = {}\n",
    "    n_classes = len(classes)\n",
    "    is_multiclass = n_classes > 2\n",
    "    is_same_y = len(np.unique(y_true)) == 1\n",
    "    R['inst'] = len(y_true)\n",
    "    \n",
    "    for c in classes:\n",
    "        R[f'inst_{c}'] = np.sum(y_true == c)\n",
    "        \n",
    "    if not is_multiclass:\n",
    "        _, cnt = np.unique(y_true, return_counts=True)\n",
    "        \n",
    "        if len(cnt) > 1:\n",
    "            R['class_ratio'] = cnt[0] / cnt[1]\n",
    "        else:\n",
    "            R['class_ratio'] = np.nan\n",
    "\n",
    "    C = confusion_matrix(y_true=y_true, y_pred=y_pred, labels=classes)\n",
    "    for (i1, c1), (i2, c2) in product(enumerate(classes), enumerate(classes)):\n",
    "        R[f'true_{c1}_pred_{c2}'] = C[i1, i2]\n",
    "\n",
    "    # Threshold Measure\n",
    "    R['acc'] = accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['bac'] = balanced_accuracy_score(y_true=y_true, y_pred=y_pred)\n",
    "    R['gmean'] = ms.gmean(np.diag(C) / np.sum(C, axis=1))\n",
    "    R['mcc'] = matthews_corrcoef(y_true=y_true, y_pred=y_pred)\n",
    "    \n",
    "    if is_multiclass:\n",
    "        for avg in ('macro', 'micro'):\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true,\n",
    "                y_pred=y_pred,\n",
    "                labels=classes,\n",
    "                average=avg, \n",
    "                zero_division=0\n",
    "            )\n",
    "            R[f'pre_{avg}'] = pre\n",
    "            R[f'rec_{avg}'] = rec\n",
    "            R[f'f1_{avg}'] = f1\n",
    "    else:\n",
    "        pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "            y_true=y_true, y_pred=y_pred, pos_label=1, average='macro', zero_division=0\n",
    "        )\n",
    "        R[f'pre_macro'] = pre\n",
    "        R[f'rec_macro'] = rec\n",
    "        R[f'f1_macro'] = f1\n",
    "        \n",
    "        for c in classes:\n",
    "            pre, rec, f1, _ = precision_recall_fscore_support(\n",
    "                y_true=y_true, y_pred=y_pred, pos_label=c, average='binary', zero_division=0\n",
    "            )\n",
    "            R[f'pre_{c}'] = pre\n",
    "            R[f'rec_{c}'] = rec\n",
    "            R[f'f1_{c}'] = f1\n",
    "\n",
    "\n",
    "\n",
    "    # ...\n",
    "\n",
    "    # Ranking Measure\n",
    "    if is_multiclass:\n",
    "        if y_prob is not None:\n",
    "            for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "                R[f'roauc_{avg}_{mc}'] = roc_auc_score(\n",
    "                    y_true=y_true, y_score=y_prob,\n",
    "                    average=avg, multi_class=mc, labels=classes\n",
    "                ) if not is_same_y else np.nan\n",
    "        else:\n",
    "            for avg, mc in product(('macro', 'micro'), ('ovr', 'ovo')):\n",
    "                R[f'roauc_{avg}_{mc}'] = np.nan\n",
    "    else:\n",
    "        if y_prob is not None:\n",
    "            R[f'roauc'] = roc_auc_score(\n",
    "                y_true=y_true, y_score=y_prob[:, 1], average=None\n",
    "            ) if not is_same_y else np.nan\n",
    "            for i, c in enumerate(classes):\n",
    "                R[f'prauc_{c}'] = average_precision_score(\n",
    "                    y_true=y_true, y_score=y_prob[:, i], pos_label=c, average=None\n",
    "                ) \n",
    "                R[f'prauc_ref_{c}'] = np.sum(y_true == c) / len(y_true)\n",
    "        else:\n",
    "            R[f'roauc'] = np.nan\n",
    "            for c in classes:\n",
    "                R[f'prauc_{c}'] = np.nan\n",
    "                R[f'prauc_ref_{c}'] = np.nan\n",
    "\n",
    "    # Probability Measure\n",
    "    if y_prob is not None:\n",
    "        R['log_loss'] = log_loss(y_true=y_true, y_pred=y_prob, labels=classes, normalize=True)\n",
    "        if not is_multiclass:\n",
    "            R[f'brier_loss'] = brier_score_loss(\n",
    "                y_true=y_true, y_prob=y_prob[:, 1], pos_label=classes[1]\n",
    "            )\n",
    "    else:\n",
    "        R['log_loss'] = np.nan\n",
    "        if not is_multiclass:\n",
    "            R[f'brier_loss'] = np.nan\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# RESULTS_EVAL = []\n",
    "# DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "# threshold = 0.5\n",
    "\n",
    "# # Loop through the desired labels\n",
    "# for l in ['stress']:\n",
    "#     dir_l = os.path.join(DIR_EVAL, l)\n",
    "#     if not os.path.exists(dir_l):\n",
    "#         continue\n",
    "\n",
    "#     for f in os.listdir(dir_l):\n",
    "#         if f == '.ipynb_checkpoints':\n",
    "#             continue\n",
    "\n",
    "#         model, pid = f[:f.index('.pkl')].split('#')\n",
    "#         res = load(os.path.join(dir_l, f))\n",
    "#         X, y = res.X_test, res.y_test\n",
    " \n",
    "#         # Perform predictions for other classifiers (without datetimes)\n",
    "#         y_pred = res.estimator.predict(X)\n",
    "\n",
    "#         if hasattr(res.estimator, 'predict_proba'):\n",
    "#             y_prob = res.estimator.predict_proba(X)\n",
    "#         else:\n",
    "#             y_prob = None\n",
    "\n",
    "#         ev_test = evaluate(\n",
    "#             y_true=y,\n",
    "#             y_pred=y_pred,\n",
    "#             y_prob=y_prob,\n",
    "#             classes=[0, 1]\n",
    "#         )\n",
    "\n",
    "#         X, y = res.X_train, res.y_train\n",
    "\n",
    "#         # Perform predictions for other classifiers (without datetimes)\n",
    "#         y_pred = res.estimator.predict(X)\n",
    "\n",
    "#         if hasattr(res.estimator, 'predict_proba'):\n",
    "#             y_prob = res.estimator.predict_proba(X)\n",
    "#         else:\n",
    "#             y_prob = None\n",
    "        \n",
    "        \n",
    "#         ev_train = evaluate(\n",
    "#             y_true=y,\n",
    "#             y_pred=y_pred,\n",
    "#             y_prob=y_prob,\n",
    "#             classes=[0, 1]\n",
    "#         )\n",
    "\n",
    "#         RESULTS_EVAL.append({\n",
    "#             'label': l,\n",
    "#             'alg': model,\n",
    "#             'split': pid,\n",
    "#             'n_feature': len(X.columns),\n",
    "#             **{f'test_{k}': v for k, v in ev_test.items()},\n",
    "#             **{f'train_{k}': v for k, v in ev_train.items()}\n",
    "#         })\n",
    "\n",
    "# RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "# RESULTS_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-24 13:31:57,102\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    label     alg split  phase  n_feature  test_inst  test_inst_0  \\\n",
      "0  stress  xgb_os   P20   test        165      520.0        297.0   \n",
      "1  stress  xgb_os   P20  train        165        NaN          NaN   \n",
      "2  stress  xgb_os   P19   test        167      619.0        556.0   \n",
      "3  stress  xgb_os   P19  train        167        NaN          NaN   \n",
      "4  stress  xgb_os   P11   test        162      452.0        361.0   \n",
      "\n",
      "   test_inst_1  test_class_ratio  test_true_0_pred_0  ...  train_pre_1  \\\n",
      "0        223.0          1.331839               290.0  ...          NaN   \n",
      "1          NaN               NaN                 NaN  ...     0.982049   \n",
      "2         63.0          8.825397               492.0  ...          NaN   \n",
      "3          NaN               NaN                 NaN  ...     0.982693   \n",
      "4         91.0          3.967033               339.0  ...          NaN   \n",
      "\n",
      "   train_rec_1  train_f1_1  train_roauc  train_prauc_0  train_prauc_ref_0  \\\n",
      "0          NaN         NaN          NaN            NaN                NaN   \n",
      "1     0.965802    0.973858     0.993766       0.991685                0.5   \n",
      "2          NaN         NaN          NaN            NaN                NaN   \n",
      "3     0.964574    0.973549     0.992872       0.990234                0.5   \n",
      "4          NaN         NaN          NaN            NaN                NaN   \n",
      "\n",
      "   train_prauc_1  train_prauc_ref_1  train_log_loss  train_brier_loss  \n",
      "0            NaN                NaN             NaN               NaN  \n",
      "1       0.995049                0.5        0.109428          0.025272  \n",
      "2            NaN                NaN             NaN               NaN  \n",
      "3       0.994412                0.5        0.115816          0.026582  \n",
      "4            NaN                NaN             NaN               NaN  \n",
      "\n",
      "[5 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ray\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def process_file(f, dir_l, l):\n",
    "    model, pid = f[:f.index('.pkl')].split('#')\n",
    "    res = load(os.path.join(dir_l, f))\n",
    "    results = []\n",
    "    \n",
    "    for phase, data in [('test', (res.X_test, res.y_test)), ('train', (res.X_train, res.y_train))]:\n",
    "        X, y = data\n",
    "        y_pred = res.estimator.predict(X)\n",
    "        \n",
    "        if hasattr(res.estimator, 'predict_proba'):\n",
    "            y_prob = res.estimator.predict_proba(X)\n",
    "        else:\n",
    "            y_prob = None\n",
    "            \n",
    "        ev = evaluate(\n",
    "            y_true=y,\n",
    "            y_pred=y_pred,\n",
    "            y_prob=y_prob,\n",
    "            classes=[0, 1]\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'label': l,\n",
    "            'alg': model,\n",
    "            'split': pid,\n",
    "            'phase': phase,\n",
    "            'n_feature': len(X.columns),\n",
    "            **{f'{phase}_{k}': v for k, v in ev.items()}\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return results\n",
    "\n",
    "DIR_EVAL = os.path.join(PATH_INTERMEDIATE, 'eval')\n",
    "RESULTS_EVAL = []\n",
    "\n",
    "futures = []\n",
    "with on_ray():\n",
    "    for l in ['stress']:\n",
    "        dir_l = os.path.join(DIR_EVAL, l)\n",
    "        if not os.path.exists(dir_l):\n",
    "            continue\n",
    "        \n",
    "        for f in os.listdir(dir_l):\n",
    "            if f == '.ipynb_checkpoints':\n",
    "                continue\n",
    "            \n",
    "            future = process_file.remote(f, dir_l, l)\n",
    "            futures.append(future)\n",
    "\n",
    "    # Collect all results\n",
    "    results = ray.get(futures)\n",
    "    for result_list in results:\n",
    "        RESULTS_EVAL.extend(result_list)\n",
    "\n",
    "    RESULTS_EVAL = pd.DataFrame(RESULTS_EVAL)\n",
    "    print(RESULTS_EVAL.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_xgbos = RESULTS_EVAL[RESULTS_EVAL['alg']=='xgb_os']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th>metric</th>\n",
       "      <th>n</th>\n",
       "      <th>cardinality</th>\n",
       "      <th>value_count</th>\n",
       "      <th>sum</th>\n",
       "      <th>mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>med</th>\n",
       "      <th>range</th>\n",
       "      <th>conf.</th>\n",
       "      <th>nan_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>split</td>\n",
       "      <td>48</td>\n",
       "      <td>24.0</td>\n",
       "      <td>P20:2, P19:2, P13:2, P23:2, P27:2, P21:2, P12:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>phase</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>test:24, train:24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>n_feature</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7754.0</td>\n",
       "      <td>161.541667</td>\n",
       "      <td>2.751853</td>\n",
       "      <td>162.0</td>\n",
       "      <td>(157, 167)</td>\n",
       "      <td>(160.74261184506273, 162.3407214882706)</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>test_inst</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13134.0</td>\n",
       "      <td>547.250000</td>\n",
       "      <td>133.651477</td>\n",
       "      <td>525.5</td>\n",
       "      <td>(268.0, nan)</td>\n",
       "      <td>(490.81393070682515, 603.6860692931749)</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stress</td>\n",
       "      <td>xgb_os</td>\n",
       "      <td>test_inst_0</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10210.0</td>\n",
       "      <td>425.416667</td>\n",
       "      <td>140.088766</td>\n",
       "      <td>388.0</td>\n",
       "      <td>(172.0, nan)</td>\n",
       "      <td>(366.26236882270996, 484.5709645106234)</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label     alg       metric   n  cardinality  \\\n",
       "0  stress  xgb_os        split  48         24.0   \n",
       "1  stress  xgb_os        phase  48          2.0   \n",
       "2  stress  xgb_os    n_feature  48          NaN   \n",
       "3  stress  xgb_os    test_inst  48          NaN   \n",
       "4  stress  xgb_os  test_inst_0  48          NaN   \n",
       "\n",
       "                                         value_count      sum        mean  \\\n",
       "0  P20:2, P19:2, P13:2, P23:2, P27:2, P21:2, P12:...      NaN         NaN   \n",
       "1                                  test:24, train:24      NaN         NaN   \n",
       "2                                                NaN   7754.0  161.541667   \n",
       "3                                                NaN  13134.0  547.250000   \n",
       "4                                                NaN  10210.0  425.416667   \n",
       "\n",
       "           SD    med         range                                    conf.  \\\n",
       "0         NaN    NaN           NaN                                      NaN   \n",
       "1         NaN    NaN           NaN                                      NaN   \n",
       "2    2.751853  162.0    (157, 167)  (160.74261184506273, 162.3407214882706)   \n",
       "3  133.651477  525.5  (268.0, nan)  (490.81393070682515, 603.6860692931749)   \n",
       "4  140.088766  388.0  (172.0, nan)  (366.26236882270996, 484.5709645106234)   \n",
       "\n",
       "   nan_count  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        0.0  \n",
       "3       24.0  \n",
       "4       24.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "SUMMARY_EVAL = []\n",
    "\n",
    "for row in RESULTS_EVAL.groupby(\n",
    "#    ['label', 'alg', 'cluster']\n",
    "     ['label', 'alg']\n",
    ").agg(summary).reset_index().itertuples():\n",
    "    for k, v in row._asdict().items():\n",
    "        if type(v) is dict:\n",
    "            r = dict(\n",
    "                label=row.label,\n",
    "                alg=row.alg,\n",
    "#                 cluster = row.cluster,\n",
    "                metric=k,\n",
    "                **v\n",
    "            )\n",
    "            SUMMARY_EVAL.append(r)\n",
    "\n",
    "SUMMARY_EVAL = pd.DataFrame(SUMMARY_EVAL)    \n",
    "SUMMARY_EVAL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">mean_sd</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>n_feature</th>\n",
       "      <th>test_acc</th>\n",
       "      <th>test_f1_1</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_pre_macro</th>\n",
       "      <th>test_rec_macro</th>\n",
       "      <th>test_roauc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>alg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stress</th>\n",
       "      <th>xgb_os</th>\n",
       "      <td>161.542 (2.752)</td>\n",
       "      <td>0.704 (0.124)</td>\n",
       "      <td>0.125 (0.083)</td>\n",
       "      <td>0.468 (0.047)</td>\n",
       "      <td>0.515 (0.032)</td>\n",
       "      <td>0.507 (0.026)</td>\n",
       "      <td>0.522 (0.057)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean_sd                                               \\\n",
       "metric               n_feature       test_acc      test_f1_1  test_f1_macro   \n",
       "label  alg                                                                    \n",
       "stress xgb_os  161.542 (2.752)  0.704 (0.124)  0.125 (0.083)  0.468 (0.047)   \n",
       "\n",
       "                                                            \n",
       "metric        test_pre_macro test_rec_macro     test_roauc  \n",
       "label  alg                                                  \n",
       "stress xgb_os  0.515 (0.032)  0.507 (0.026)  0.522 (0.057)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUB_SUMMARY_EVAL = SUMMARY_EVAL.loc[\n",
    "    lambda x: x['metric'].isin(\n",
    "        ['n_feature','test_acc' ,'test_f1_1',  'test_f1_macro','test_roauc','test_pre_macro','test_rec_macro']\n",
    "    )\n",
    "].round(3).assign(\n",
    "    mean_sd=lambda x: x['mean'].astype(str).str.cat(' (' + x['SD'].astype(str) + ')', sep=''),\n",
    ").pivot(\n",
    "    index=['label', 'alg'], columns=['metric'], values=['mean_sd']\n",
    ")\n",
    "\n",
    "# separate rows where 'alg' is 'dummy' and 'alg' is not 'dummy'\n",
    "df_dummy = SUB_SUMMARY_EVAL[SUB_SUMMARY_EVAL.index.get_level_values('alg') == 'dummy']\n",
    "df_others = SUB_SUMMARY_EVAL[SUB_SUMMARY_EVAL.index.get_level_values('alg') != 'dummy']\n",
    "\n",
    "# concatenate them ensuring that 'dummy' rows are always at the top for each group\n",
    "SUB_SUMMARY_EVAL = pd.concat([df_dummy, df_others])\n",
    "\n",
    "SUB_SUMMARY_EVAL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
