{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Funcs.Utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = os.path.join(PATH_INTERMEDIATE, 'feat',f'stress-fixed-15min.pkl')\n",
    "\n",
    "X, y, groups, t, datetimes = load(p)\n",
    "##############################################\n",
    "# #Remove users with extreme label distribution\n",
    "# # Create a DataFrame from y, groups, t, datetimes\n",
    "# info_df = pd.DataFrame({\n",
    "#     'y': y,\n",
    "#     'groups': groups,\n",
    "#     't': t,\n",
    "#     'datetimes': pd.to_datetime(datetimes)  # assuming 'datetimes' needs conversion to datetime\n",
    "# })\n",
    "\n",
    "# # Calculate majority/minority ratio for each group\n",
    "# def calculate_ratio(group):\n",
    "#     counts = group['y'].value_counts()\n",
    "#     if len(counts) > 1:\n",
    "#         majority = counts.max()\n",
    "#         minority = counts.min()\n",
    "#         ratio = majority / minority\n",
    "#     else:\n",
    "#         ratio = np.inf  # Infinite ratio if there's no minority class\n",
    "#     return ratio\n",
    "\n",
    "# # Apply the function per group\n",
    "# group_ratios = info_df.groupby('groups').apply(calculate_ratio)\n",
    "\n",
    "# # Filter groups based on the ratio\n",
    "# filtered_groups = group_ratios[group_ratios <= 4].index\n",
    "\n",
    "# # Filter the original DataFrame 'info_df' to remove skewed groups\n",
    "# filtered_info = info_df[info_df['groups'].isin(filtered_groups)]\n",
    "\n",
    "# # Use the indices of the filtered info to refine 'X'\n",
    "# X_filtered = X.loc[filtered_info.index]\n",
    "\n",
    "# # Extracting other arrays from the filtered info\n",
    "# y_filtered = filtered_info['y'].values\n",
    "# groups_filtered = filtered_info['groups'].values\n",
    "# t_filtered = filtered_info['t'].values\n",
    "# datetimes_filtered = filtered_info['datetimes'].values\n",
    "\n",
    "# X, y, groups, t, datetimes = X_filtered, y_filtered, groups_filtered, t_filtered, datetimes_filtered\n",
    "\n",
    "# Now 'X_filtered', 'y_filtered', 'groups_filtered', 't_filtered', 'datetimes_filtered'\n",
    "# are ready to be used for further analysis or modeling\n",
    "################################################\n",
    "# #Remove neutral state samples\n",
    "# y =  LABELS_PROC['stressLevel'].to_numpy()\n",
    "\n",
    "# # Create a mask that selects all samples where y is not equal to 3 (neutral state)\n",
    "# mask = y != 3\n",
    "\n",
    "# # Apply this mask to filter out the neutral samples from all arrays\n",
    "# X_filtered = X[mask]  # X is a DataFrame, it uses boolean indexing directly\n",
    "# y_filtered = y[mask]  # y, groups, t, datetimes are numpy arrays or similar structures\n",
    "# groups_filtered = groups[mask]\n",
    "# t_filtered = t[mask]\n",
    "# datetimes_filtered = datetimes[mask]\n",
    "\n",
    "# y = (y_filtered > 3).astype(int)\n",
    "# X = X_filtered\n",
    "# groups = groups_filtered\n",
    "# t = t_filtered\n",
    "# datetimes = datetimes_filtered\n",
    "\n",
    "################################################\n",
    "#Use mean threshold for all users (only training set,\\ \n",
    "#we need to use raw value and binarize after data splitting)\n",
    "# y =  LABELS_PROC['stressLevel'].to_numpy()\n",
    "#Use user speicifc mean threshold\n",
    "# y =LABELS_PROC['stress_user_mean'].to_numpy()\n",
    "#Use fixed threshold\n",
    "#         y =LABELS_PROC['stress_fixed'].to_numpy()\n",
    "#Use three categories (fixed threshold) \n",
    "#        y =LABELS_PROC['stress_fixed_tri'].to_numpy()\n",
    "\n",
    "\n",
    "#The following code is designed for reordering for the sake of time series split \n",
    "#################################################\n",
    "# Create a DataFrame with user_id and datetime\n",
    "\n",
    "df = pd.DataFrame({'user_id': groups, 'datetime': datetimes, 'label': y})\n",
    "\n",
    "# df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "\n",
    "# Normalize the datetime for each user only needed for timeseries split/groupk partil personalization\n",
    "#         df_merged['datetime'] = df_merged.groupby('user_id')['datetime'].transform(lambda x: x - x.min())\n",
    "# df_merged['datetime'] = df_merged.groupby('user_id')['datetime'].transform(lambda x: x - x.min().normalize())\n",
    "\n",
    "# Sort the DataFrame by datetime\n",
    "df_merged = df_merged.sort_values(by=['user_id', 'datetime'])\n",
    "# df_merged = df_merged.sort_values(by=['datetime'])\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "# df_merged = df_merged.sample(frac=1, random_state=RANDOM_STATE)\n",
    "\n",
    "# Update groups and datetimes\n",
    "groups = df_merged['user_id'].to_numpy()\n",
    "datetimes = df_merged['datetime'].to_numpy()  \n",
    "y = df_merged['label'].to_numpy()\n",
    "X = df_merged.drop(columns=['user_id', 'datetime', 'label'])\n",
    "\n",
    "#The following code is for shuffling the temporal order for all users\n",
    "########################################################\n",
    "\n",
    "# # Assuming 'groups', 'datetimes', 'y', and 'X' are already defined and loaded\n",
    "# # Create a DataFrame with user_id, datetime, and label\n",
    "# df = pd.DataFrame({\n",
    "#     'user_id': groups,\n",
    "#     'datetime': datetimes,\n",
    "#     'label': y\n",
    "# })\n",
    "\n",
    "# # Merge the new DataFrame with the features DataFrame 'X'\n",
    "# # Ensure 'X' is indexed the same way as 'groups', 'datetimes', and 'y'\n",
    "# df_merged = pd.merge(df, X, left_index=True, right_index=True)\n",
    "\n",
    "# # Shuffle the DataFrame\n",
    "# # This disregards the temporal ordering completely and randomizes all entries\n",
    "# df_merged = df_merged.sample(frac=1, random_state=42)  # Use a fixed seed for reproducibility\n",
    "\n",
    "# # Extract the shuffled 'groups', 'datetimes', 'y', and 'X' from the shuffled DataFrame\n",
    "# groups_shuffled = df_merged['user_id'].to_numpy()\n",
    "# datetimes_shuffled = df_merged['datetime'].to_numpy()\n",
    "# y_shuffled = df_merged['label'].to_numpy()\n",
    "# X_shuffled = df_merged.drop(columns=['user_id', 'datetime', 'label'])\n",
    "\n",
    "# # Optionally, you can convert 'X_shuffled' back to the correct type if it needs to be a DataFrame\n",
    "# X_shuffled = pd.DataFrame(X_shuffled, columns=X.columns)\n",
    "\n",
    "# X, y, groups, datetimes = X_shuffled, y_shuffled, groups_shuffled, datetimes_shuffled\n",
    "\n",
    "\n",
    "#The following code is for only using 1st day\n",
    "###########################################\n",
    "# filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "# # filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_week.csv'),index_col=0)\n",
    "# X_filtered = X[~X.index.isin(filtered_df.index)]\n",
    "# y_series = pd.Series(y, index=X.index)\n",
    "# y_filtered = y_series[~y_series.index.isin(filtered_df.index)]\n",
    "# y_filtered = y_filtered.values\n",
    "# groups_series = pd.Series(groups, index=X.index)\n",
    "# groups_filtered = groups_series[~groups_series.index.isin(filtered_df.index)]\n",
    "# groups_filtered = groups_filtered.values\n",
    "# X,y, groups=X_filtered,y_filtered, groups_filtered\n",
    "# #The following code is for excluding using 1st day\n",
    "# ###########################################\n",
    "# # filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_week.csv'),index_col=0)\n",
    "# filtered_df = pd.read_csv(os.path.join(PATH_INTERMEDIATE,'exclude_1st_day.csv'),index_col=0)\n",
    "# X_filtered = X[X.index.isin(filtered_df.index)]\n",
    "# y_series = pd.Series(y, index=X.index)\n",
    "# y_filtered = y_series[y_series.index.isin(filtered_df.index)]\n",
    "# y_filtered = y_filtered.values\n",
    "# groups_series = pd.Series(groups, index=X.index)\n",
    "# groups_filtered = groups_series[groups_series.index.isin(filtered_df.index)]\n",
    "# groups_filtered = groups_filtered.values\n",
    "# datetimes_series = pd.Series(datetimes, index=X.index)\n",
    "# datetimes_filtered = datetimes_series[datetimes_series.index.isin(filtered_df.index)]\n",
    "# datetimes_filtered = datetimes_filtered.values\n",
    "# X,y, groups, datetimes=X_filtered,y_filtered, groups_filtered, datetimes_filtered\n",
    "\n",
    "\n",
    "###########################################\n",
    "#The following code is for similar-user model\n",
    "###########################################\n",
    "#         similar_user = pd.read_csv(os.path.join(PATH_INTERMEDIATE,  'similar_user.csv'))\n",
    "#         cluster_label = similar_user['cluster'].value_counts().index[0] #N number clusters\n",
    "#         similar_users_in_cluster = similar_user[similar_user['cluster'] == cluster_label]['pcode']\n",
    "\n",
    "#         # Check if each value in 'groups' is in 'similar_users_in_cluster'\n",
    "#         mask = np.isin(groups, similar_users_in_cluster)\n",
    "\n",
    "#         # Filter 'groups' based on the mask\n",
    "#         filtered_groups = groups[mask]\n",
    "#         # Filter 'X' and 'y' based on the mask\n",
    "#         X_filtered = X[mask]\n",
    "#         y_filtered = y[mask]\n",
    "#         X,y, groups=X_filtered,y_filtered, filtered_groups\n",
    "###########################################\n",
    "#Remove low frequency features\n",
    "#         mask = ['CAE#', 'MED#', 'ONF#', 'PWS#', 'RNG#','MSG#' ]\n",
    "#         X = X.loc[:, [all(m not in str(x) for m in mask) for x in X.columns]]\n",
    "\n",
    "#Divide the features into different categories\n",
    "feat_current = X.loc[:,[('#VAL' in str(x)) or ('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_dsc = X.loc[:,[('#DSC' in str(x))  for x in X.keys()]]  \n",
    "feat_yesterday = X.loc[:,[('Yesterday' in str(x))  for x in X.keys()]]  \n",
    "feat_today = X.loc[:,[('Today' in str(x))  for x in X.keys()]]  \n",
    "feat_sleep = X.loc[:,[('Sleep' in str(x))  for x in X.keys()]]  \n",
    "feat_time = X.loc[:,[('Time' in str(x))  for x in X.keys()]]  \n",
    "feat_pif = X.loc[:,[('PIF' in str(x))  for x in X.keys()]]  \n",
    "feat_ImmediatePast = X.loc[:,[('ImmediatePast_15' in str(x))  for x in X.keys()]]\n",
    "#Divide the time window features into sensor/past stress label\n",
    "feat_current_sensor = X.loc[:,[('#VAL' in str(x))  for x in X.keys()]]  \n",
    "feat_current_ESM = X.loc[:,[('ESM#LastLabel' in str(x)) for x in X.keys()]]  \n",
    "feat_ImmediatePast_sensor = feat_ImmediatePast.loc[:,[('ESM' not in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_ImmediatePast_ESM = feat_ImmediatePast.loc[:,[('ESM'  in str(x)) for x in feat_ImmediatePast.keys()]]  \n",
    "feat_today_sensor = feat_today.loc[:,[('ESM' not in str(x))  for x in feat_today.keys()]]  \n",
    "feat_today_ESM = feat_today.loc[:,[('ESM'  in str(x)) for x in feat_today.keys()]]  \n",
    "feat_yesterday_sensor = feat_yesterday.loc[:,[('ESM' not in str(x)) for x in feat_yesterday.keys()]]  \n",
    "feat_yesterday_ESM = feat_yesterday.loc[:,[('ESM'  in str(x)) for x in feat_yesterday.keys()]]\n",
    "\n",
    "\n",
    "\n",
    "#Prepare the final feature set\n",
    "feat_baseline = pd.concat([ feat_time,feat_dsc,feat_current_sensor, feat_ImmediatePast_sensor],axis=1)\n",
    "#The following code is for calculating aggregated features\n",
    "########################################################################\n",
    "# # Define a function to split the column name into sensor and attribute\n",
    "# def split_column_name(col_name):\n",
    "#     parts = col_name.rsplit(\"#\", 1)  # Split on last occurrence of '#'\n",
    "#     return parts[0]  # This gives you 'Sensor#Attribute'\n",
    "\n",
    "# # Get a list of unique sensor-attribute combinations\n",
    "# df=feat_today_sensor\n",
    "# sensor_attributes = df.columns.map(split_column_name).unique()\n",
    "\n",
    "# # Create a list to hold the aggregated results\n",
    "# agg_results = []\n",
    "\n",
    "# # Loop over each sensor-attribute, select the appropriate columns, compute the mean and std\n",
    "# for sensor_attribute in sensor_attributes:\n",
    "#     # Select columns for this sensor-attribute\n",
    "#     cols_to_aggregate = [col for col in df.columns if col.startswith(sensor_attribute)]\n",
    "#     # Compute the mean and std and store in the new DataFrame\n",
    "#     agg_results.append(df[cols_to_aggregate].mean(axis=1).rename(sensor_attribute + '|'+ 'MEAN'))\n",
    "#     agg_results.append(df[cols_to_aggregate].std(axis=1).rename(sensor_attribute + '|'+'STD'))\n",
    "\n",
    "# # Concatenate all the results into a single DataFrame\n",
    "# agg_feature = pd.concat(agg_results, axis=1)\n",
    "\n",
    "######################################################################\n",
    "feat_final = pd.concat([feat_baseline],axis=1)\n",
    "\n",
    "#         # Fill NaN values with zeros\n",
    "#         feat_final = feat_final.fillna(0)\n",
    "\n",
    "#         # Find the maximum non-infinity value and minimum non-negative infinity value across the entire dataframe\n",
    "#         max_val = feat_final[feat_final != np.inf].max().max()\n",
    "#         min_val = feat_final[feat_final != -np.inf].min().min()\n",
    "\n",
    "#         # Replace positive and negative infinity values\n",
    "#         feat_final.replace(np.inf, max_val, inplace=True)\n",
    "#         feat_final.replace(-np.inf, min_val, inplace=True)\n",
    "\n",
    "X = feat_final\n",
    "cats = X.columns[X.dtypes == bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from typing import Union\n",
    "\n",
    "\n",
    "class EvXGBClassifier(BaseEstimator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        eval_size=None,\n",
    "        eval_metric='logloss',\n",
    "        early_stopping_rounds=10,\n",
    "        random_state=None,\n",
    "        **kwargs\n",
    "        ):\n",
    "        self.random_state = random_state\n",
    "        self.eval_size = eval_size\n",
    "        self.eval_metric = eval_metric\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.model = XGBClassifier(\n",
    "            random_state=self.random_state,\n",
    "            eval_metric=self.eval_metric,\n",
    "            early_stopping_rounds=self.early_stopping_rounds,\n",
    "            # tree_method='gpu_hist',  # Use GPU histogram method\n",
    "            # predictor='gpu_predictor',  # Ensure predictions also use GPU\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.model.classes_\n",
    "\n",
    "    @property\n",
    "    def feature_importances_(self):\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    @property\n",
    "    def feature_names_in_(self):\n",
    "        return self.model.feature_names_in_\n",
    "\n",
    "    def fit(self, X: Union[pd.DataFrame, np.ndarray], y: np.ndarray):\n",
    "        if self.eval_size:\n",
    "            splitter = StratifiedShuffleSplit(random_state=self.random_state, test_size=self.eval_size)\n",
    "            I_train, I_eval = next(splitter.split(X, y))\n",
    "            if isinstance(X, pd.DataFrame):\n",
    "                X_train, y_train = X.iloc[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X.iloc[I_eval, :], y[I_eval]\n",
    "            else:\n",
    "                X_train, y_train = X[I_train, :], y[I_train]\n",
    "                X_eval, y_eval = X[I_eval, :], y[I_eval]\n",
    "                \n",
    "            self.model = self.model.fit(\n",
    "                X=X_train, y=y_train, \n",
    "                eval_set=[(X_eval, y_eval)],\n",
    "                verbose=False\n",
    "            )\n",
    "        else:\n",
    "            self.model = self.model.fit(X=X, y=y, verbose=False)\n",
    "        # After fitting, store the best iteration\n",
    "        self.best_iteration_ = self.model.get_booster().best_iteration\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "#         return self.model.predict(X)\n",
    "        return self.model.predict(X, iteration_range=(0, self.best_iteration_ + 1))\n",
    "\n",
    "    def predict_proba(self, X: pd.DataFrame):\n",
    "#         return self.model.predict_proba(X)\n",
    "        return self.model.predict_proba(X, iteration_range=(0, self.best_iteration_ + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 21:04:27,914\tINFO worker.py:1612 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(train_fold pid=645922)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(train_fold pid=645929)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645914)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645928)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645925)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(train_fold pid=645930)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(train_fold pid=645913)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645911)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645910)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(train_fold pid=645908)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "0.5221456449377896\n",
      "\u001b[2m\u001b[36m(train_fold pid=645918)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import ray\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold, LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    metrics: dict\n",
    "    duration: float\n",
    "\n",
    "def log(message: str):\n",
    "    print(message)  # Simple logging to stdout or enhance as needed\n",
    "\n",
    "@ray.remote\n",
    "def train_fold(dir_result: str, fold_name: str, X_train, y_train, X_test, y_test, C_cat, C_num, estimator, normalize, select, oversample, random_state):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        if normalize:\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "        \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            \n",
    "        if select:\n",
    "            # # Removing low variance features\n",
    "            # X_train = exclude_low_variance(X_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            # #Removing highly correlated features\n",
    "            # X_train = remove_pairwise_corr(X_train, outcome_variable= y_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            if isinstance(select, SelectFromModel):\n",
    "                select = [select]\n",
    "                \n",
    "            for i, s in enumerate(select):\n",
    "                C = np.asarray(X_train.columns)\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "\n",
    "        if oversample:\n",
    "            if len(C_cat) > 0:\n",
    "                sampler = SMOTENC(categorical_features=[X_train.columns.get_loc(c) for c in C_cat], random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = clone(estimator).fit(X_train, y_train)\n",
    "        y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, y_pred, average=None)\n",
    "\n",
    "        result = FoldResult(\n",
    "            name=fold_name,\n",
    "            metrics={'AUC': auc_score},\n",
    "            duration=time.time() - start_time\n",
    "        )\n",
    "        log(f'Training completed for {fold_name} with AUC: {auc_score}')\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f'Error in {fold_name}: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "def perform_cross_validation(X, y, groups, estimator, normalize=False, select=None, oversample=False, random_state=None):\n",
    "    if not ray.is_initialized():\n",
    "        ray.init()\n",
    "\n",
    "    futures = []\n",
    "    splitter = LeaveOneGroupOut()  # Or any other CV strategy\n",
    "    for idx, (train_idx, test_idx) in enumerate(splitter.split(X, y, groups)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        C_cat = np.asarray(sorted(cats))\n",
    "        C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "        job = train_fold.remote('path_to_results', f'Fold_{idx}', X_train, y_train, X_test, y_test, C_cat, C_num, estimator, normalize, select, oversample, random_state)\n",
    "        futures.append(job)\n",
    "\n",
    "    results = ray.get(futures)\n",
    "    return results\n",
    "\n",
    "with on_ray():\n",
    "    SELECT_LASSO = SelectFromModel(\n",
    "            estimator=LogisticRegression(\n",
    "            penalty='l1' \n",
    "            ,solver='liblinear'\n",
    "            , C=1, random_state=RANDOM_STATE, max_iter=4000\n",
    "        ),\n",
    "        threshold = 0.005\n",
    "    )\n",
    "    # Example usage\n",
    "    estimator = EvXGBClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        eval_metric='logloss', \n",
    "        eval_size=0.2,\n",
    "        early_stopping_rounds=10, \n",
    "        objective='binary:logistic', \n",
    "        verbosity=0,\n",
    "        learning_rate=0.01,\n",
    "    )  \n",
    "    results = perform_cross_validation(X, y, groups, estimator, normalize=True, select=[SELECT_LASSO], oversample=True, random_state=42)\n",
    "    auc_values = [results[i].metrics['AUC'] for i in range(len(results))]\n",
    "    mean_auc = np.mean(auc_values)\n",
    "    print(mean_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-23 19:10:47</td></tr>\n",
       "<tr><td>Running for: </td><td>01:38:23.30        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.7/62.6 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=0 total_brackets=3<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=100.0%): {TERMINATED: 5} <br>  Bracket(Max Size (n)=3, Milestone (r)=54, completed=100.0%): {TERMINATED: 11} <br>  Bracket(Max Size (n)=15, Milestone (r)=9, completed=1.7%): {PENDING: 1, RUNNING: 10, TERMINATED: 7} <br>Logical resource usage: 10.0/32 CPUs, 0.9999999999999999/1 GPUs (0.0/2.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">   early_stopping_round\n",
       "s</th><th style=\"text-align: right;\">     gamma</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  num_parallel_tree</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">     loss</th><th style=\"text-align: right;\">     auc</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_32387bf9</td><td>RUNNING   </td><td>143.248.57.67:628124</td><td style=\"text-align: right;\">           0.875449</td><td style=\"text-align: right;\">          0.816065</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.231311  </td><td style=\"text-align: right;\">      0.12983  </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.00491184 </td><td style=\"text-align: right;\">    1.04221 </td><td style=\"text-align: right;\">   0.886848</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_13ffd7e9</td><td>RUNNING   </td><td>143.248.57.67:628159</td><td style=\"text-align: right;\">           0.720136</td><td style=\"text-align: right;\">          0.812212</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.164751  </td><td style=\"text-align: right;\">      0.0534863</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.51395    </td><td style=\"text-align: right;\">    0.579313</td><td style=\"text-align: right;\">   0.966701</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_d6f26804</td><td>RUNNING   </td><td>143.248.57.67:628198</td><td style=\"text-align: right;\">           0.661548</td><td style=\"text-align: right;\">          0.953088</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.2882    </td><td style=\"text-align: right;\">      0.0206438</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.186022   </td><td style=\"text-align: right;\">    3.78687 </td><td style=\"text-align: right;\">   0.810023</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_ebeb56e5</td><td>RUNNING   </td><td>143.248.57.67:628232</td><td style=\"text-align: right;\">           0.938978</td><td style=\"text-align: right;\">          0.85539 </td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.203055  </td><td style=\"text-align: right;\">      0.0127826</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.98803    </td><td style=\"text-align: right;\">    2.03136 </td><td style=\"text-align: right;\">   0.735912</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_53b4a9f2</td><td>RUNNING   </td><td>143.248.57.67:628272</td><td style=\"text-align: right;\">           0.850391</td><td style=\"text-align: right;\">          0.898968</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.15389   </td><td style=\"text-align: right;\">      0.0126381</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.7769     </td><td style=\"text-align: right;\">    4.72871 </td><td style=\"text-align: right;\">   0.659821</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_e41a7932</td><td>RUNNING   </td><td>143.248.57.67:628339</td><td style=\"text-align: right;\">           0.530907</td><td style=\"text-align: right;\">          0.922081</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.201596  </td><td style=\"text-align: right;\">      0.0952534</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.28553    </td><td style=\"text-align: right;\">    4.93765 </td><td style=\"text-align: right;\">   0.609329</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_037bbd88</td><td>RUNNING   </td><td>143.248.57.67:628377</td><td style=\"text-align: right;\">           0.715528</td><td style=\"text-align: right;\">          0.639563</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.490784  </td><td style=\"text-align: right;\">      0.0839027</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.36471    </td><td style=\"text-align: right;\">    0.623256</td><td style=\"text-align: right;\">   0.886432</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_164252da</td><td>RUNNING   </td><td>143.248.57.67:628411</td><td style=\"text-align: right;\">           0.503025</td><td style=\"text-align: right;\">          0.662783</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.307014  </td><td style=\"text-align: right;\">      0.0132683</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.73597    </td><td style=\"text-align: right;\">    0.848123</td><td style=\"text-align: right;\">   0.927828</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_67615173</td><td>RUNNING   </td><td>143.248.57.67:628446</td><td style=\"text-align: right;\">           0.678935</td><td style=\"text-align: right;\">          0.798045</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.266803  </td><td style=\"text-align: right;\">      0.130421 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">1.96934    </td><td style=\"text-align: right;\">    1.40018 </td><td style=\"text-align: right;\">   0.862511</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_45b30780</td><td>RUNNING   </td><td>143.248.57.67:628479</td><td style=\"text-align: right;\">           0.919031</td><td style=\"text-align: right;\">          0.976854</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.45163   </td><td style=\"text-align: right;\">      0.0113219</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.799164   </td><td style=\"text-align: right;\">    2.11481 </td><td style=\"text-align: right;\">   0.748299</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_7597332f</td><td>PENDING   </td><td>                    </td><td style=\"text-align: right;\">           0.892256</td><td style=\"text-align: right;\">          0.992351</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.483507  </td><td style=\"text-align: right;\">      0.0564748</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.582671   </td><td style=\"text-align: right;\">    1.98072 </td><td style=\"text-align: right;\">   0.894932</td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">         </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>objective_de5e5f61</td><td>TERMINATED</td><td>143.248.57.67:626119</td><td style=\"text-align: right;\">           0.751506</td><td style=\"text-align: right;\">          0.90605 </td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.430433  </td><td style=\"text-align: right;\">      0.0154811</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">1.0429     </td><td style=\"text-align: right;\">    1.78722 </td><td style=\"text-align: right;\">   0.623913</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3443.09</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_a8884a9e</td><td>TERMINATED</td><td>143.248.57.67:626149</td><td style=\"text-align: right;\">           0.566353</td><td style=\"text-align: right;\">          0.703549</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.106856  </td><td style=\"text-align: right;\">      0.0345129</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">1.61665    </td><td style=\"text-align: right;\">    2.44683 </td><td style=\"text-align: right;\">   0.913103</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1995.16</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_ad27cb72</td><td>TERMINATED</td><td>143.248.57.67:626179</td><td style=\"text-align: right;\">           0.992767</td><td style=\"text-align: right;\">          0.930806</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.0834449 </td><td style=\"text-align: right;\">      0.066459 </td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.991557   </td><td style=\"text-align: right;\">    2.96908 </td><td style=\"text-align: right;\">   0.777629</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1940.15</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_178204f1</td><td>TERMINATED</td><td>143.248.57.67:626209</td><td style=\"text-align: right;\">           0.822056</td><td style=\"text-align: right;\">          0.523905</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.0611931 </td><td style=\"text-align: right;\">      0.0422924</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.04327    </td><td style=\"text-align: right;\">    3.45147 </td><td style=\"text-align: right;\">   0.783073</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1940.8 </td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_8f52ba75</td><td>TERMINATED</td><td>143.248.57.67:626239</td><td style=\"text-align: right;\">           0.970259</td><td style=\"text-align: right;\">          0.759856</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.342807  </td><td style=\"text-align: right;\">      0.0108108</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">1.45384    </td><td style=\"text-align: right;\">    3.3467  </td><td style=\"text-align: right;\">   0.731719</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2533.44</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_5a242966</td><td>TERMINATED</td><td>143.248.57.67:626270</td><td style=\"text-align: right;\">           0.780525</td><td style=\"text-align: right;\">          0.53323 </td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.0942873 </td><td style=\"text-align: right;\">      0.0345656</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.396217   </td><td style=\"text-align: right;\">    3.33455 </td><td style=\"text-align: right;\">   0.623044</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1953.79</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_1363952d</td><td>TERMINATED</td><td>143.248.57.67:626301</td><td style=\"text-align: right;\">           0.693483</td><td style=\"text-align: right;\">          0.642183</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.417769  </td><td style=\"text-align: right;\">      0.016879 </td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">1.6043     </td><td style=\"text-align: right;\">    1.68477 </td><td style=\"text-align: right;\">   0.695464</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2240.09</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_04a979a5</td><td>TERMINATED</td><td>143.248.57.67:626332</td><td style=\"text-align: right;\">           0.755428</td><td style=\"text-align: right;\">          0.758875</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.396176  </td><td style=\"text-align: right;\">      0.0367284</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.749138   </td><td style=\"text-align: right;\">    4.2712  </td><td style=\"text-align: right;\">   0.992962</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1968.18</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_cb43f6c0</td><td>TERMINATED</td><td>143.248.57.67:626363</td><td style=\"text-align: right;\">           0.634693</td><td style=\"text-align: right;\">          0.731835</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.0131865 </td><td style=\"text-align: right;\">      0.0408643</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">1.84804    </td><td style=\"text-align: right;\">    1.21674 </td><td style=\"text-align: right;\">   0.762275</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1936.68</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_f8f4dc99</td><td>TERMINATED</td><td>143.248.57.67:626395</td><td style=\"text-align: right;\">           0.786335</td><td style=\"text-align: right;\">          0.853533</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.0774402 </td><td style=\"text-align: right;\">      0.022276 </td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.229255   </td><td style=\"text-align: right;\">    1.58289 </td><td style=\"text-align: right;\">   0.819293</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2039.49</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_86365fb3</td><td>TERMINATED</td><td>143.248.57.67:627621</td><td style=\"text-align: right;\">           0.596188</td><td style=\"text-align: right;\">          0.582562</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.393353  </td><td style=\"text-align: right;\">      0.0287381</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">0.320743   </td><td style=\"text-align: right;\">    2.32178 </td><td style=\"text-align: right;\">   0.712844</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1929.63</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_8d4ffd73</td><td>TERMINATED</td><td>143.248.57.67:627652</td><td style=\"text-align: right;\">           0.767785</td><td style=\"text-align: right;\">          0.992816</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.0618247 </td><td style=\"text-align: right;\">      0.0286329</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.000615653</td><td style=\"text-align: right;\">    0.642953</td><td style=\"text-align: right;\">   0.984809</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1963.62</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_c553d570</td><td>TERMINATED</td><td>143.248.57.67:627683</td><td style=\"text-align: right;\">           0.586375</td><td style=\"text-align: right;\">          0.731997</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.128964  </td><td style=\"text-align: right;\">      0.0265883</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">1.55325    </td><td style=\"text-align: right;\">    4.36997 </td><td style=\"text-align: right;\">   0.69989 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         3824.84</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_772ee1c0</td><td>TERMINATED</td><td>143.248.57.67:627717</td><td style=\"text-align: right;\">           0.652156</td><td style=\"text-align: right;\">          0.934324</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.0874274 </td><td style=\"text-align: right;\">      0.0184173</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 2</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">0.261972   </td><td style=\"text-align: right;\">    4.35141 </td><td style=\"text-align: right;\">   0.653373</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2115.54</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_795fd681</td><td>TERMINATED</td><td>143.248.57.67:627750</td><td style=\"text-align: right;\">           0.812455</td><td style=\"text-align: right;\">          0.546313</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.327022  </td><td style=\"text-align: right;\">      0.0161612</td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.2027     </td><td style=\"text-align: right;\">    3.4337  </td><td style=\"text-align: right;\">   0.84826 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1944.21</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_317adcd5</td><td>TERMINATED</td><td>143.248.57.67:627783</td><td style=\"text-align: right;\">           0.771782</td><td style=\"text-align: right;\">          0.879785</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.192924  </td><td style=\"text-align: right;\">      0.0153763</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">1.79638    </td><td style=\"text-align: right;\">    0.721058</td><td style=\"text-align: right;\">   0.68451 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2316.29</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_d1c06e27</td><td>TERMINATED</td><td>143.248.57.67:627822</td><td style=\"text-align: right;\">           0.621096</td><td style=\"text-align: right;\">          0.73848 </td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.0348916 </td><td style=\"text-align: right;\">      0.0215757</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">0.744001   </td><td style=\"text-align: right;\">    2.60723 </td><td style=\"text-align: right;\">   0.949758</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1963.19</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_675aad9f</td><td>TERMINATED</td><td>143.248.57.67:627863</td><td style=\"text-align: right;\">           0.99915 </td><td style=\"text-align: right;\">          0.872746</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.383182  </td><td style=\"text-align: right;\">      0.0317102</td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">1.08725    </td><td style=\"text-align: right;\">    1.51599 </td><td style=\"text-align: right;\">   0.77245 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2085.6 </td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_4def1983</td><td>TERMINATED</td><td>143.248.57.67:627904</td><td style=\"text-align: right;\">           0.506317</td><td style=\"text-align: right;\">          0.530664</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.165717  </td><td style=\"text-align: right;\">      0.187607 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">0.221764   </td><td style=\"text-align: right;\">    3.22636 </td><td style=\"text-align: right;\">   0.643882</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1978.91</td><td style=\"text-align: right;\">-0.521162</td><td style=\"text-align: right;\">0.521162</td></tr>\n",
       "<tr><td>objective_6f87f0a3</td><td>TERMINATED</td><td>143.248.57.67:627969</td><td style=\"text-align: right;\">           0.579989</td><td style=\"text-align: right;\">          0.623168</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.357187  </td><td style=\"text-align: right;\">      0.0360976</td><td style=\"text-align: right;\">          4</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">1.46083    </td><td style=\"text-align: right;\">    0.522446</td><td style=\"text-align: right;\">   0.925819</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         2181.17</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_2ddcd156</td><td>TERMINATED</td><td>143.248.57.67:628020</td><td style=\"text-align: right;\">           0.691497</td><td style=\"text-align: right;\">          0.81625 </td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.259224  </td><td style=\"text-align: right;\">      0.0669814</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">1.91112    </td><td style=\"text-align: right;\">    1.2244  </td><td style=\"text-align: right;\">   0.838882</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1944.76</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_aa12a670</td><td>TERMINATED</td><td>143.248.57.67:628054</td><td style=\"text-align: right;\">           0.885866</td><td style=\"text-align: right;\">          0.97939 </td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.474426  </td><td style=\"text-align: right;\">      0.0102369</td><td style=\"text-align: right;\">          5</td><td style=\"text-align: right;\">                 3</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.660721   </td><td style=\"text-align: right;\">    1.98835 </td><td style=\"text-align: right;\">   0.841783</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1930.25</td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "<tr><td>objective_6e0824f2</td><td>TERMINATED</td><td>143.248.57.67:628086</td><td style=\"text-align: right;\">           0.900075</td><td style=\"text-align: right;\">          0.999814</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.00236513</td><td style=\"text-align: right;\">      0.0631397</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">0.041223   </td><td style=\"text-align: right;\">    0.867608</td><td style=\"text-align: right;\">   0.998604</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1942.2 </td><td style=\"text-align: right;\">-0.522146</td><td style=\"text-align: right;\">0.522146</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\u001b[32m [repeated 5x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=626363)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=626270)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=626179)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=626209)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=626332)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=626149)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=626395)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626301)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=626239)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=626119)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_10 with AUC: 0.49551569506726456\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_14 with AUC: 0.45376\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\n",
      "\u001b[2m\u001b[36m(objective pid=627621)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=627652)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=627750)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627822)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627717)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_15 with AUC: 0.5383122073769555\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627783)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627863)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627904)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_2 with AUC: 0.5286225402504472\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_3 with AUC: 0.5834963649977055\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_4 with AUC: 0.48616463505400176\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_5 with AUC: 0.5454074910596649\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_6 with AUC: 0.5516264038991311\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_7 with AUC: 0.5682494103168906\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_10 with AUC: 0.4998996051134462\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_8 with AUC: 0.5804693921037412\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_9 with AUC: 0.45851449275362316\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_11 with AUC: 0.5257388565891472\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_17 with AUC: 0.5660980810234542\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_12 with AUC: 0.526619728797293\n",
      "\u001b[2m\u001b[36m(objective pid=627683)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_18 with AUC: 0.48996205165870976\n",
      "\u001b[2m\u001b[36m(objective pid=627969)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_13 with AUC: 0.461340676728335\n",
      "\u001b[2m\u001b[36m(objective pid=628020)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_19 with AUC: 0.5908889645776567\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_14 with AUC: 0.47832\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_22 with AUC: 0.5355537319823034\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628198)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_20 with AUC: 0.5144894483974943\n",
      "\u001b[2m\u001b[36m(objective pid=628232)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628339)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_15 with AUC: 0.5329736211031175\n",
      "\u001b[2m\u001b[36m(objective pid=628054)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628159)\u001b[0m Training completed for Fold_21 with AUC: 0.3647486108321617\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628086)\u001b[0m Training completed for Fold_23 with AUC: 0.44988807488807486\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[2m\u001b[36m(objective pid=628124)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628411)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n",
      "\u001b[2m\u001b[36m(objective pid=628272)\u001b[0m Training completed for Fold_16 with AUC: 0.5222025939514728\n",
      "\u001b[2m\u001b[36m(objective pid=628339)\u001b[0m Training completed for Fold_1 with AUC: 0.5542485955056179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 19:10:47,961\tWARNING tune.py:192 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-04-23 19:10:57,987\tINFO tune.py:1148 -- Total run time: 5913.83 seconds (5903.29 seconds for the tuning loop).\n",
      "2024-04-23 19:10:57,988\tWARNING tune.py:1163 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2024-04-23 19:10:58,006\tWARNING experiment_analysis.py:916 -- Failed to read the results for 11 trials:\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_32387bf9_24_colsample_bylevel=0.8754,colsample_bytree=0.8161,early_stopping_rounds=10,gamma=0.2313,learning_rate=0.1298,_2024-04-23_18-37-48\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_13ffd7e9_25_colsample_bylevel=0.7201,colsample_bytree=0.8122,early_stopping_rounds=10,gamma=0.1648,learning_rate=0.0535,_2024-04-23_18-39-22\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_d6f26804_26_colsample_bylevel=0.6615,colsample_bytree=0.9531,early_stopping_rounds=10,gamma=0.2882,learning_rate=0.0206,_2024-04-23_18-40-23\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_ebeb56e5_27_colsample_bylevel=0.9390,colsample_bytree=0.8554,early_stopping_rounds=10,gamma=0.2031,learning_rate=0.0128,_2024-04-23_18-44-21\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_53b4a9f2_28_colsample_bylevel=0.8504,colsample_bytree=0.8990,early_stopping_rounds=10,gamma=0.1539,learning_rate=0.0126,_2024-04-23_18-44-40\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_e41a7932_29_colsample_bylevel=0.5309,colsample_bytree=0.9221,early_stopping_rounds=10,gamma=0.2016,learning_rate=0.0953,_2024-04-23_18-47-45\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_037bbd88_30_colsample_bylevel=0.7155,colsample_bytree=0.6396,early_stopping_rounds=10,gamma=0.4908,learning_rate=0.0839,_2024-04-23_19-06-13\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_164252da_31_colsample_bylevel=0.5030,colsample_bytree=0.6628,early_stopping_rounds=10,gamma=0.3070,learning_rate=0.0133,_2024-04-23_19-08-40\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_67615173_32_colsample_bylevel=0.6789,colsample_bytree=0.7980,early_stopping_rounds=10,gamma=0.2668,learning_rate=0.1304,_2024-04-23_19-09-26\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_45b30780_33_colsample_bylevel=0.9190,colsample_bytree=0.9769,early_stopping_rounds=10,gamma=0.4516,learning_rate=0.0113,_2024-04-23_19-09-49\n",
      "- /home/iclab/ray_results/objective_2024-04-23_17-32-24/objective_7597332f_34_colsample_bylevel=0.8923,colsample_bytree=0.9924,early_stopping_rounds=10,gamma=0.4835,learning_rate=0.0565,_2024-04-23_19-10-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(objective pid=628377)\u001b[0m Training completed for Fold_0 with AUC: 0.61597210692346\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, hp, fmin, tpe\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from ray import tune\n",
    "from ray.tune import with_parameters\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "import traceback\n",
    "import ray\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class FoldResult:\n",
    "    name: str\n",
    "    metrics: dict\n",
    "    duration: float\n",
    "\n",
    "def log(message: str):\n",
    "    print(message)  # Simple logging to stdout or enhance as needed\n",
    "\n",
    "def train_fold(dir_result: str, fold_name: str, X_train, y_train, X_test, y_test, C_cat, C_num, estimator, normalize, select, oversample, random_state):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        if normalize:\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "        \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            \n",
    "        if select:\n",
    "            # # Removing low variance features\n",
    "            # X_train = exclude_low_variance(X_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            # #Removing highly correlated features\n",
    "            # X_train = remove_pairwise_corr(X_train, outcome_variable= y_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            if isinstance(select, SelectFromModel):\n",
    "                select = [select]\n",
    "                \n",
    "            for i, s in enumerate(select):\n",
    "                C = np.asarray(X_train.columns)\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "\n",
    "        if oversample:\n",
    "            if len(C_cat) > 0:\n",
    "                sampler = SMOTENC(categorical_features=[X_train.columns.get_loc(c) for c in C_cat], random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        estimator = clone(estimator).fit(X_train, y_train)\n",
    "        y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, y_pred, average=None)\n",
    "\n",
    "        result = FoldResult(\n",
    "            name=fold_name,\n",
    "            metrics={'AUC': auc_score},\n",
    "            duration=time.time() - start_time\n",
    "        )\n",
    "        log(f'Training completed for {fold_name} with AUC: {auc_score}')\n",
    "        return result\n",
    "\n",
    "    except Exception as e:\n",
    "        log(f'Error in {fold_name}: {traceback.format_exc()}')\n",
    "        return None\n",
    "\n",
    "def perform_cross_validation(X, y, groups, estimator, normalize=False, select=None, oversample=False, random_state=None):\n",
    "    if not ray.is_initialized():\n",
    "        ray.init()\n",
    "\n",
    "    futures = []\n",
    "    splitter = LeaveOneGroupOut()  # Or any other CV strategy\n",
    "    for idx, (train_idx, test_idx) in enumerate(splitter.split(X, y, groups)):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        C_cat = np.asarray(sorted(cats))\n",
    "        C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "        job = train_fold('path_to_results', f'Fold_{idx}', X_train, y_train, X_test, y_test, C_cat, C_num, estimator, normalize, select, oversample, random_state)\n",
    "        futures.append(job)\n",
    "\n",
    "    results = futures\n",
    "    return results\n",
    "\n",
    "def objective(params, X, y, groups):\n",
    "    SELECT_LASSO = SelectFromModel(\n",
    "            estimator=LogisticRegression(\n",
    "            penalty='l1' \n",
    "            ,solver='liblinear'\n",
    "            , C=1, random_state=RANDOM_STATE, max_iter=4000\n",
    "        ),\n",
    "        threshold = 0.005\n",
    "    )\n",
    "    # Example usage\n",
    "    estimator = EvXGBClassifier(\n",
    "        random_state=RANDOM_STATE, \n",
    "        eval_metric='logloss', \n",
    "        eval_size=0.2,\n",
    "        objective='binary:logistic', \n",
    "        verbosity=0,\n",
    "        **params\n",
    "    )  \n",
    "\n",
    "    results = perform_cross_validation(X, y, groups, estimator, normalize=True, select=[SELECT_LASSO], oversample=True, random_state=42)\n",
    "    auc_values = [results[i].metrics['AUC'] for i in range(len(results))]\n",
    "\n",
    "    mean_auc = np.mean(auc_values)\n",
    "    return {'loss': -mean_auc, 'auc': mean_auc, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(3, 11)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 250, 500]),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.5, 5.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'num_parallel_tree': hp.choice('num_parallel_tree', [1, 10, 20]),\n",
    "    'early_stopping_rounds': hp.choice('early_stopping_rounds', [10, 30, 50]),\n",
    "}\n",
    "\n",
    "# Setup HyperOpt search with Ray Tune\n",
    "algo = HyperOptSearch(space, metric=\"auc\", mode=\"max\")\n",
    "\n",
    "# Define the scheduler for early stopping\n",
    "scheduler = HyperBandScheduler(time_attr=\"training_iteration\", metric=\"auc\", mode=\"max\")\n",
    "with on_ray():\n",
    "    # Assuming X, y, and groups are predefined datasets\n",
    "    analysis = tune.run(\n",
    "        with_parameters(objective, X=X, y=y, groups=groups),\n",
    "        num_samples=100,\n",
    "        search_alg=algo,\n",
    "        resources_per_trial={\"cpu\": 1, \"gpu\": 0.1},\n",
    "        verbose=1,\n",
    "        scheduler=scheduler\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analysis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Explicitly specify the metric and mode when fetching the best trial\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m best_trial \u001b[38;5;241m=\u001b[39m \u001b[43manalysis\u001b[49m\u001b[38;5;241m.\u001b[39mget_best_trial(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mconfig))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial AUC: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(best_trial\u001b[38;5;241m.\u001b[39mlast_result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'analysis' is not defined"
     ]
    }
   ],
   "source": [
    "# Explicitly specify the metric and mode when fetching the best trial\n",
    "best_trial = analysis.get_best_trial(metric=\"auc\", mode=\"max\")\n",
    "print(\"Best trial config: {}\".format(best_trial.config))\n",
    "print(\"Best trial AUC: {}\".format(best_trial.last_result[\"auc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize data\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# select_svc = SELECT_SVC.fit(X_train, y_train)\n",
    "# X_train = select_svc.transform(X_train)\n",
    "# X_test = select_svc.transform(X_test)\n",
    "\n",
    "# # Apply SMOTE for handling imbalanced data\n",
    "# X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:47:12,414\tINFO worker.py:1431 -- Connecting to existing Ray cluster at address: 143.248.57.77:6379...\n",
      "2024-04-23 23:47:12,417\tINFO worker.py:1612 -- Connected to Ray cluster. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:47:12,947\tINFO tune.py:657 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-04-23 23:54:13</td></tr>\n",
       "<tr><td>Running for: </td><td>00:07:00.77        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.2/62.6 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using HyperBand: num_stopped=0 total_brackets=2<br>Round #0:<br>  Bracket(Max Size (n)=5, Milestone (r)=81, completed=0.0%): {RUNNING: 5} <br>  Bracket(Max Size (n)=8, Milestone (r)=27, completed=0.0%): {RUNNING: 5} <br>Logical resource usage: 10.0/28 CPUs, 0/2 GPUs (0.0/2.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  colsample_bylevel</th><th style=\"text-align: right;\">  colsample_bytree</th><th style=\"text-align: right;\">   early_stopping_round\n",
       "s</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  max_depth</th><th style=\"text-align: right;\">  min_child_weight</th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  num_parallel_tree</th><th style=\"text-align: right;\">  random_state</th><th style=\"text-align: right;\">  reg_alpha</th><th style=\"text-align: right;\">  reg_lambda</th><th style=\"text-align: right;\">  subsample</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>objective_b7f3d8c8</td><td>RUNNING </td><td>143.248.57.67:689208</td><td style=\"text-align: right;\">           0.98042 </td><td style=\"text-align: right;\">          0.930601</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.338221</td><td style=\"text-align: right;\">      0.0103042</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           100</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.9908  </td><td style=\"text-align: right;\">    0.851487</td><td style=\"text-align: right;\">   0.874733</td></tr>\n",
       "<tr><td>objective_d7444ff0</td><td>RUNNING </td><td>143.248.57.67:689240</td><td style=\"text-align: right;\">           0.950857</td><td style=\"text-align: right;\">          0.617655</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.425368</td><td style=\"text-align: right;\">      0.0328206</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   0.7241  </td><td style=\"text-align: right;\">    2.79618 </td><td style=\"text-align: right;\">   0.930185</td></tr>\n",
       "<tr><td>objective_318801dc</td><td>RUNNING </td><td>143.248.57.67:689278</td><td style=\"text-align: right;\">           0.711216</td><td style=\"text-align: right;\">          0.706371</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.144302</td><td style=\"text-align: right;\">      0.116178 </td><td style=\"text-align: right;\">          7</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.78992 </td><td style=\"text-align: right;\">    1.43218 </td><td style=\"text-align: right;\">   0.725533</td></tr>\n",
       "<tr><td>objective_1647bf36</td><td>RUNNING </td><td>143.248.57.67:689316</td><td style=\"text-align: right;\">           0.771336</td><td style=\"text-align: right;\">          0.728683</td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.364951</td><td style=\"text-align: right;\">      0.0575058</td><td style=\"text-align: right;\">         10</td><td style=\"text-align: right;\">                 6</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.81503 </td><td style=\"text-align: right;\">    2.32184 </td><td style=\"text-align: right;\">   0.747001</td></tr>\n",
       "<tr><td>objective_d5d2704f</td><td>RUNNING </td><td>143.248.57.67:689354</td><td style=\"text-align: right;\">           0.683279</td><td style=\"text-align: right;\">          0.7343  </td><td style=\"text-align: right;\">30</td><td style=\"text-align: right;\">0.335284</td><td style=\"text-align: right;\">      0.140009 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   0.504216</td><td style=\"text-align: right;\">    0.525385</td><td style=\"text-align: right;\">   0.947775</td></tr>\n",
       "<tr><td>objective_5fc63bf8</td><td>RUNNING </td><td>143.248.57.67:689581</td><td style=\"text-align: right;\">           0.922574</td><td style=\"text-align: right;\">          0.583568</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.251905</td><td style=\"text-align: right;\">      0.0272598</td><td style=\"text-align: right;\">          3</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.90272 </td><td style=\"text-align: right;\">    1.7274  </td><td style=\"text-align: right;\">   0.877489</td></tr>\n",
       "<tr><td>objective_88b4561f</td><td>RUNNING </td><td>143.248.57.67:689612</td><td style=\"text-align: right;\">           0.946463</td><td style=\"text-align: right;\">          0.889774</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.23937 </td><td style=\"text-align: right;\">      0.156832 </td><td style=\"text-align: right;\">          6</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.01955 </td><td style=\"text-align: right;\">    3.67613 </td><td style=\"text-align: right;\">   0.651641</td></tr>\n",
       "<tr><td>objective_57758949</td><td>RUNNING </td><td>143.248.57.67:689643</td><td style=\"text-align: right;\">           0.640862</td><td style=\"text-align: right;\">          0.773857</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.265961</td><td style=\"text-align: right;\">      0.101306 </td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 4</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                 10</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.23842 </td><td style=\"text-align: right;\">    1.16954 </td><td style=\"text-align: right;\">   0.675476</td></tr>\n",
       "<tr><td>objective_f6ed92a5</td><td>RUNNING </td><td>143.248.57.67:689675</td><td style=\"text-align: right;\">           0.521575</td><td style=\"text-align: right;\">          0.758485</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">0.117711</td><td style=\"text-align: right;\">      0.0113122</td><td style=\"text-align: right;\">          8</td><td style=\"text-align: right;\">                 5</td><td style=\"text-align: right;\">           250</td><td style=\"text-align: right;\">                 20</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.42355 </td><td style=\"text-align: right;\">    3.11951 </td><td style=\"text-align: right;\">   0.727441</td></tr>\n",
       "<tr><td>objective_bb2f3115</td><td>RUNNING </td><td>143.248.57.67:689706</td><td style=\"text-align: right;\">           0.715923</td><td style=\"text-align: right;\">          0.527408</td><td style=\"text-align: right;\">50</td><td style=\"text-align: right;\">0.440399</td><td style=\"text-align: right;\">      0.0362518</td><td style=\"text-align: right;\">          9</td><td style=\"text-align: right;\">                 1</td><td style=\"text-align: right;\">           500</td><td style=\"text-align: right;\">                  1</td><td style=\"text-align: right;\">            42</td><td style=\"text-align: right;\">   1.35731 </td><td style=\"text-align: right;\">    1.3379  </td><td style=\"text-align: right;\">   0.944732</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-23 23:54:13,716\tWARNING tune.py:192 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-04-23 23:54:23,735\tINFO tune.py:1148 -- Total run time: 430.79 seconds (420.76 seconds for the tuning loop).\n",
      "2024-04-23 23:54:23,736\tWARNING tune.py:1163 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n",
      "2024-04-23 23:54:23,738\tWARNING experiment_analysis.py:916 -- Failed to read the results for 10 trials:\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_b7f3d8c8_1_colsample_bylevel=0.9804,colsample_bytree=0.9306,early_stopping_rounds=10,gamma=0.3382,learning_rate=0.0103,m_2024-04-23_23-47-12\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_d7444ff0_2_colsample_bylevel=0.9509,colsample_bytree=0.6177,early_stopping_rounds=50,gamma=0.4254,learning_rate=0.0328,m_2024-04-23_23-47-13\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_318801dc_3_colsample_bylevel=0.7112,colsample_bytree=0.7064,early_stopping_rounds=50,gamma=0.1443,learning_rate=0.1162,m_2024-04-23_23-47-14\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_1647bf36_4_colsample_bylevel=0.7713,colsample_bytree=0.7287,early_stopping_rounds=30,gamma=0.3650,learning_rate=0.0575,m_2024-04-23_23-47-15\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_d5d2704f_5_colsample_bylevel=0.6833,colsample_bytree=0.7343,early_stopping_rounds=30,gamma=0.3353,learning_rate=0.1400,m_2024-04-23_23-47-17\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_5fc63bf8_6_colsample_bylevel=0.9226,colsample_bytree=0.5836,early_stopping_rounds=50,gamma=0.2519,learning_rate=0.0273,m_2024-04-23_23-47-18\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_88b4561f_7_colsample_bylevel=0.9465,colsample_bytree=0.8898,early_stopping_rounds=10,gamma=0.2394,learning_rate=0.1568,m_2024-04-23_23-47-19\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_57758949_8_colsample_bylevel=0.6409,colsample_bytree=0.7739,early_stopping_rounds=10,gamma=0.2660,learning_rate=0.1013,m_2024-04-23_23-47-20\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_f6ed92a5_9_colsample_bylevel=0.5216,colsample_bytree=0.7585,early_stopping_rounds=10,gamma=0.1177,learning_rate=0.0113,m_2024-04-23_23-47-21\n",
      "- /home/iclab/ray_results/objective_2024-04-23_23-47-12/objective_bb2f3115_10_colsample_bylevel=0.7159,colsample_bytree=0.5274,early_stopping_rounds=50,gamma=0.4404,learning_rate=0.0363,_2024-04-23_23-47-23\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from hyperopt import STATUS_OK, Trials, hp, fmin, tpe\n",
    "from sklearn.model_selection import train_test_split, LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from ray import tune\n",
    "from ray.tune import with_parameters\n",
    "from ray.tune.schedulers import HyperBandScheduler\n",
    "from ray.tune.search.hyperopt import HyperOptSearch\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import time\n",
    "import traceback\n",
    "import ray\n",
    "from sklearn.base import clone\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "SELECT_SVC = SelectFromModel(\n",
    "#     estimator=LinearSVC(\n",
    "#         penalty='l1',\n",
    "#         loss='squared_hinge',\n",
    "#         dual=False,\n",
    "#         tol=1e-3,\n",
    "#         C=1e-2,\n",
    "#         max_iter=5000,\n",
    "#         random_state=RANDOM_STATE\n",
    "#     ),\n",
    "#     threshold=1e-5\n",
    "    \n",
    "        estimator=LogisticRegression(\n",
    "        penalty='l1' \n",
    "        ,solver='liblinear'\n",
    "        , C=1, random_state=RANDOM_STATE, max_iter=4000\n",
    "    ),\n",
    "    threshold = 0.005\n",
    ")\n",
    "\n",
    "\n",
    "def objective(params, X, y, groups):\n",
    "    scaler = StandardScaler()\n",
    "    logo = LeaveOneGroupOut()\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, test_idx in logo.split(X, y, groups):\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        ##########################\n",
    "        normalize = True\n",
    "        select = [SELECT_SVC]\n",
    "        oversample = True\n",
    "        random_state = 42\n",
    "\n",
    "\n",
    "        C_cat = np.asarray(sorted(cats))\n",
    "        C_num = np.asarray(sorted(X.columns[~X.columns.isin(C_cat)]))\n",
    "\n",
    "\n",
    "        if normalize:\n",
    "            X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "            X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "            \n",
    "            scaler = StandardScaler().fit(X_train_N)\n",
    "            X_train_N = scaler.transform(X_train_N)\n",
    "            X_test_N = scaler.transform(X_test_N)\n",
    "        \n",
    "            X_train = pd.DataFrame(\n",
    "                np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            X_test = pd.DataFrame(\n",
    "                np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                columns=np.concatenate((C_cat, C_num))\n",
    "            )\n",
    "            \n",
    "        if select:\n",
    "            # # Removing low variance features\n",
    "            # X_train = exclude_low_variance(X_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            # #Removing highly correlated features\n",
    "            # X_train = remove_pairwise_corr(X_train, outcome_variable= y_train)\n",
    "            # X_test = X_test[X_train.columns]  # Keep only the selected features in the test set\n",
    "\n",
    "            if isinstance(select, SelectFromModel):\n",
    "                select = [select]\n",
    "                \n",
    "            for i, s in enumerate(select):\n",
    "                C = np.asarray(X_train.columns)\n",
    "                M = s.fit(X=X_train.values, y=y_train).get_support()\n",
    "                C_sel = C[M]\n",
    "                C_cat = C_cat[np.isin(C_cat, C_sel)]\n",
    "                C_num = C_num[np.isin(C_num, C_sel)]\n",
    "                \n",
    "                X_train_N, X_test_N = X_train[C_num].values, X_test[C_num].values\n",
    "                X_train_C, X_test_C = X_train[C_cat].values, X_test[C_cat].values\n",
    "\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    np.concatenate((X_train_C, X_train_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    np.concatenate((X_test_C, X_test_N), axis=1),\n",
    "                    columns=np.concatenate((C_cat, C_num))\n",
    "                )\n",
    "\n",
    "        if oversample:\n",
    "            if len(C_cat) > 0:\n",
    "                sampler = SMOTENC(categorical_features=[X_train.columns.get_loc(c) for c in C_cat], random_state=random_state)\n",
    "            else:\n",
    "                sampler = SMOTE(random_state=random_state)\n",
    "            X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "        ##########################\n",
    "\n",
    "\n",
    "        # Split training data for early stopping\n",
    "        X_train_sub, X_val, y_train_sub, y_val = train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=int(params['random_state'])\n",
    "        )\n",
    "        \n",
    "        # # Classifier\n",
    "        # clf = xgb.XGBClassifier(\n",
    "        #     objective='binary:logistic',\n",
    "        #     eval_metric='auc',\n",
    "        #     verbosity=0,\n",
    "        #     tree_method='hist',\n",
    "        #     **params\n",
    "        # )\n",
    "        # clf.fit(\n",
    "        #     X_train_sub, y_train_sub,\n",
    "        #     eval_set=[(X_val, y_val)],\n",
    "        #     verbose=False\n",
    "        # )\n",
    "\n",
    "        # best_iteration = clf.best_iteration\n",
    "        # y_pred = clf.predict_proba(X_test, iteration_range=(0, best_iteration + 1))[:, 1]\n",
    "        # auc_score = roc_auc_score(y_test, y_pred)\n",
    "        estimator = EvXGBClassifier(\n",
    "        eval_metric='logloss', \n",
    "        eval_size=0.2,\n",
    "        objective='binary:logistic', \n",
    "        verbosity=0,\n",
    "        **params\n",
    "        )  \n",
    "        estimator = clone(estimator).fit(X_train, y_train)\n",
    "        y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "        auc_score = roc_auc_score(y_test, y_pred, average=None)\n",
    "        \n",
    "        auc_scores.append(auc_score)\n",
    "\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    return {'loss': -mean_auc, 'auc': mean_auc, 'status': STATUS_OK}\n",
    "\n",
    "space = {\n",
    "    'max_depth': hp.choice('max_depth', range(3, 11)),\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 6, 1),\n",
    "    'subsample': hp.uniform('subsample', 0.6, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "    'colsample_bylevel': hp.uniform('colsample_bylevel', 0.5, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 0.5),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.01), np.log(0.2)),\n",
    "    'n_estimators': hp.choice('n_estimators', [100, 250, 500]),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.5, 5.0),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 2.0),\n",
    "    'num_parallel_tree': hp.choice('num_parallel_tree', [1, 10, 20]),\n",
    "    'early_stopping_rounds': hp.choice('early_stopping_rounds', [10, 30, 50]),\n",
    "    'random_state': hp.choice('random_state', [42])\n",
    "}\n",
    "\n",
    "# Setup HyperOpt search with Ray Tune\n",
    "algo = HyperOptSearch(space, metric=\"auc\", mode=\"max\")\n",
    "\n",
    "# Define the scheduler for early stopping\n",
    "scheduler = HyperBandScheduler(time_attr=\"training_iteration\", metric=\"auc\", mode=\"max\")\n",
    "with on_ray():\n",
    "    # Assuming X, y, and groups are predefined datasets\n",
    "    analysis = tune.run(\n",
    "        with_parameters(objective, X=X, y=y, groups=groups),\n",
    "        num_samples=10,\n",
    "        search_alg=algo,\n",
    "        resources_per_trial={\"cpu\": 1},\n",
    "        verbose=2,\n",
    "        scheduler=scheduler\n",
    "        \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sci-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
